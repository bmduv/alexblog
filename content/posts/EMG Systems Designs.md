---
title: EMG Systems Designs
draft: false
tags:
---
# Electromyography Signal Acquisition and Processing
Electrical activities generated by skeletal muscles represent the core EMG signal. These signals are generated from motor neurons which are part of the central nervous system. 
- Amplitude is the positive peak to negative peak voltage
- Phase is the time duration of the initial negative cycle
- Rise time is the time interval between negative and positive peaks
- There are three turns in the EMG signal -> the duration is defined as the total time between two negative cycles
- Satellite is a small signal followed by the main EMG signal![[imgs/emgsys1.jpg]]
- Advantage of EMG over ECG and EEG is that ECG and EEG signals are below 100 Hz whereas EMG signals cover the range from 5 Hz to 2kHz
- Common issues:
   - noise in EMG data
   - low data quality + inadequate and undisclosed data

# A Smart Approach to EMG Envelope Extraction and Powerful Denoising for HMI
EMG signals largely affected by powerline interference and motion artifacts + boards that directly provide EMG envelope without denoising raw signal is often unreliable and hinder HMI performance. But sophisticated filtering provides high performance but is not viable when power and computation sources are limited. Potential of feed-forward comb (FFC) filters to remove both powerline interferences and motion artifacts from EMG. 
- FFC filter and EMG envelope extractor can be implemented without computing multiplication -> suitable for low-cost, low-power platforms. 
- EMG Linear Envelope (EMG-LE): combination of raw EMG signal rectification and low pass filtering / can also be estimated by computing local root mean square value of raw EMG via sliding window -> EMG-LE  gives a measure of local signal power
- Powerline: electromagnetic interference caused by capacitive or inductive coupling between EMG electrodes and the powerline in surrounding environment. PLI makes 50 Hz or 60 Hz sinewave
- Motion Artifacts: come from body motion, increase of muscle cross-section, and resulting slippage of various tissues and skin layers. 
   - According to International Society of Electrophysiology and Kinesiology standards, frequency band of diagnostic EMG signal ranges from 5-10 Hz up to 400-500 Hz. Motion Artifacts are generally confined to very low frequencies, typically bellow 20-30 Hz. 
Feedforward Comb Filter Equation:
$$
y(k) = x(k) = \alpha{x}(k-N)
$$
- Where x is input signal, N is delay expressed in number of samples, and $\alpha$ is parameter that regulates some aspects of the filter behavior. When $\alpha$ is equal to $\pm$ 1, the minima of the FFC amplitude response are equal to zero. This is used to cancel out specific frequency components, such as the fundamental frequency of powerline interference and its harmonics.

# CTRL-LABS: GENERIC NONINVASVE NEUROMOTER INTERFACE FOR HCI
- sEMG device (wearable) is a dry-electrode, multi-channel recording platform with much higher sample rates (2kHz / 2000 samples per second) and is able to extract single putative MUAPs + with high SNR (Signal Noise Ratio)
   - Single putative MUAP: MUAPs (motor unit action potentials) that are identified as originating from a single motor unit based on shape, amplitude, and timing characteristics (usually hypothesized to belong to single motor unit from pattern recognition)
- Deployed neural networks trained on data from thousands of human participants using custom automated behavioral prompting and participant selection system to scale neuromotor recordings across a large and diverse population.
- Following were the main tests for decoding actions:
   - 1D continuous navigation (akin to pointing laser-pointer based on wrist posture)
   - gesture detection (finger pinches + thumb swipes)
   - handwriting transcription
- In offline evaluation, sEMG-RD platform achieved greater than 90% classification accuracy for held-out participants in handwriting and gesture detection + greater than 75% accuracy on wrist pose classification + 0.5 target acquisitions er second in wrist pose-based continuous navigation + 0.9 acquisitions per second on discrete gestures + 17.0 adjusted words per minute with handwriting
## Data Collection
Continuous navigation:
- participants prompted to flex, extend, or deviate their wrist
Discrete gesture detection:
- participants prompted to perform nine distinct gestures with randomized gesture order and inter-gesture interval
Handwriting task:
- participants prompted to hold their fingers together (as if holding an imaginary writing implement) and "write" the prompted text
During data collection, recorded both sEMG activity and timestamps of labels on the prompter using real-time processing engine.
- designed the engine to be used during recording and model inference to reduce online-offline shift
- to precisely align prompter labels to actual gesture times, which may vary due to participant's reaction time/compliance, developed time alignment algorithm that allowed for post hoc inference of gesture event times
Due to high sensitivity of sEMG-RD, allowed for observation of fine differences in sEMG power across instances of given gesture performed as well as revealing highly structured patterns of activity.
## Single-participant sEMG Models do not Generalize Across Individuals
To evaluate ability of obtaining performant sEMG decoders across sessions for a given participant, trained single-participant models for 100 participants who had collected at least five sessions of discrete gesture classification task with nine different gestures. For each participant, held out one session for evaluation and trained models on the remaining four sessions. As offline evaluation metric, used Classification Error Rate (CLER) -> one minus number of correct predictions divided by the total number of true events.
- Single-participant models trained and tested on same participant achieved offline performance that improved substantially with more training data (median CLER 50.6% with $\pm$ 21.7 SEM with 2 training sessions to median CLER 26.5% $\pm$ 15.3% SEM with all 4 training sessions)
- But models trained on one participant and then tested on another showed substantially worse performance and benefited only mildly from increasing amount of training data
- Indicates significant domain shift across people -> for most people, model trained on their own data performed better compared to all other single-participant models + for all 100 people, their own model was within the top 5 performing models
- Cross-participant variability difficult: because there is structure or clusters across people or every individual require relatively unique single-participant model?
   - Using t-SNE for two-dimensional embedding with distance between two participants being average of the model transfer CLER between them -> absence of clear structure suggests that there are no immediately clear clusters of participants with quantitatively distinct performance statistics. There are no people who exhibit capacity to generate performant models for other people nor are there people for whom other people's models always perform well + receiver score (CLER for specific participant using models for all other participant) vs. donor score (CLER for each participant when using model of specific participant) are weakly correlated and show high error rates.
## Offline Evaluation of Generic Models
To train generic models able to generalize across people, collected large quantities of data from thousands of data collection participants. For each task, data collected open-loop to train decoding models.
- Open-loop: process in which data is gathered from a system or experiment without any feedback mechanism influencing data collection process
Looked at offline decoding performance of models trained on varying quantities of data + offline evaluation was performed entirely on held-out participants as a way of estimating model performance for a participant whose data was not included in the training set.
Function fit to the empirical performance data is an inverse power law both as a function of parameters and data quantity, consistent with scaling properties of large language models.
Observed reliable performance improvements as a function of increasing number of participants in the training corpus as well as overall better performance for larger models.
## Online Evaluation of Generic Models
Closed-loop performance of sEMG decoding models is main metric that confirms HCI utility.
- Closed-loop: process in which experiment is conducted with feedback loop, where output of model is continuously monitored and used to adjust the inputs to achieve desired outcome
For each task, closed-loop evaluation performed on naive participants who had not previously had meaningful experience using any sEMG decoder (same N=20 for wrist and handwriting, N=24 separate participants for discrete gestures)
- For each task, participants performed 3 distinct blocks of trials to allow for characterization of learning with first block always being practice block (10 trials for discrete gestures and handwriting, 50 trials for wrist post)
- For all tasks, participants improved with experience
- During practice block, study supervisor gave verbal coaching as needed to participants to encourage them to learn the gestures to complete each task.
For wrist post control, performance was characterized by time to target acquisition and dial-in time (time taken to get back to target after exiting it prematurely)
- While offline classification metrics for the wrist pose decoder showed meaningful rates of misclassification, use of model for closed-loop continuous control supported reasonable performance.
For discrete gestures, performance on the discrete task was characterized by measure of how often the first detected gesture following a prompt matched the prompted gesture as well as how long it took to complete each prompted gesture. (Acquisition rates improved with practice, but first hit probabilities did not -> participants were likely adapting to the task rather than to the model)
For closed-loop handwriting, performance was characterized by character error rate and speed of text entry.
## Representations Learned by Discrete Gesture Model
Neural Network architecture consisted of 1D Convolutional Layer, followed by 3 Recurrent LSTM Layers, and then a classification layer. 
- Visualization of CNN: used representative filers alongside putative MUAPs detected using wristband -> filters appear to form coarse basis set spanning the statistics of MUAPs
- Visualization of LSTM: used changing representational geometry across layers (LSTM hidden unit activity) -> analyzed representation of four properties: gesture category, participant identity, band placement, and gesture-evoked sEMG power (proxy for behavioral variability over executions of same gesture)
   - Examining dominant principal components, observed trend of gesture category becoming more separable deeper in the network (representations of each gesture became more tightly clustered and less sensitive to nuisance variables)
## Personalizing sEMG Handwriting Models Improves Average Performance
Fine-tuned generic model's parameters using additional supervised data from set of 40 participants not included in training data of generic model (specifically for handwriting task). Held out single session for each participant for evaluation.
- Fine-tuning improved average CER for all amounts of additional data and for all numbers of pre-training participants -> but, as model was pre-trained with data from more participants, absolute and relative improvements in CER from personalization diminished
- Personalization significantly improved performance of poorly performing participants across all generic models.